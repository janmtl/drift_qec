{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=2, linewidth=120)\n",
    "from copy import copy\n",
    "from tqdm import *\n",
    "from drift_qec.Q import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regime 1 basis alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "D = 0.25*np.pi\n",
    "N_TRIALS = 1000\n",
    "MAX_N = int(1e6)\n",
    "N_STEP = int(1e3)\n",
    "RECORDS = []\n",
    "for trial in tqdm(range(N_TRIALS)):\n",
    "    channel = Channel(kx=0.7, ky=0.2, kz=0.1,\n",
    "                      Q=np.linalg.qr(np.random.randn(3,3))[0],\n",
    "                      n=N_STEP, d=D)\n",
    "    pxhat, pyhat, pzhat = list(np.linalg.svd(channel.Mhat)[1])\n",
    "    RECORDS.append({\n",
    "            \"trial\": trial,\n",
    "            \"time\": 0,\n",
    "            \"d\": channel.d,\n",
    "            \"Mdist\": np.linalg.norm(channel.Mhat-channel.C),\n",
    "            \"Qdist\": np.linalg.norm(np.dot(channel.Qc.T, channel.Q) - np.eye(3)),\n",
    "            \"pxval\": channel.kx, \"pyval\": channel.ky, \"pzval\": channel.kz,\n",
    "            \"pxhat\": pxhat, \"pyhat\": pyhat, \"pzhat\": pzhat\n",
    "        })\n",
    "    for time in range(0, MAX_N, N_STEP):\n",
    "        channel.update()\n",
    "        pxhat, pyhat, pzhat = list(np.linalg.svd(channel.Mhat)[1])\n",
    "        lowest_p = np.min([pxhat, pyhat, pzhat])\n",
    "        channel.d = D * lowest_p\n",
    "        RECORDS.append({\n",
    "                \"trial\": trial,\n",
    "                \"time\": time,\n",
    "                \"d\": channel.d,\n",
    "                \"Mdist\": np.linalg.norm(channel.Mhat-channel.C),\n",
    "                \"Qdist\": np.linalg.norm(np.dot(channel.Qc.T, channel.Q) - np.eye(3)),\n",
    "                \"pxval\": channel.kx, \"pyval\": channel.ky, \"pzval\": channel.kz,\n",
    "                \"pxhat\": pxhat, \"pyhat\": pyhat, \"pzhat\": pzhat\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(RECORDS)\n",
    "df.to_csv(\"regime1_adaptive_delta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "D = 0.25*np.pi\n",
    "N_TRIALS = 1000\n",
    "MAX_N = int(1e6)\n",
    "N_STEP = int(1e3)\n",
    "RECORDS = []\n",
    "for trial in tqdm(range(N_TRIALS)):\n",
    "    channel = Channel(kx=0.985, ky=0.01, kz=0.005,\n",
    "                      Q=np.linalg.qr(np.random.randn(3,3))[0],\n",
    "                      n=N_STEP, d=D)\n",
    "    pxhat, pyhat, pzhat = list(np.linalg.svd(channel.Mhat)[1])\n",
    "    RECORDS.append({\n",
    "            \"trial\": trial,\n",
    "            \"time\": 0,\n",
    "            \"d\": channel.d,\n",
    "            \"Mdist\": np.linalg.norm(channel.Mhat-channel.C),\n",
    "            \"Qdist\": np.linalg.norm(np.dot(channel.Qc.T, channel.Q) - np.eye(3)),\n",
    "            \"pxval\": channel.kx, \"pyval\": channel.ky, \"pzval\": channel.kz,\n",
    "            \"pxhat\": pxhat, \"pyhat\": pyhat, \"pzhat\": pzhat\n",
    "        })\n",
    "    for time in range(0, MAX_N, N_STEP):\n",
    "        channel.update()\n",
    "        pxhat, pyhat, pzhat = list(np.linalg.svd(channel.Mhat)[1])\n",
    "        lowest_p = np.min([pxhat, pyhat, pzhat])\n",
    "        channel.d = D * lowest_p\n",
    "        RECORDS.append({\n",
    "                \"trial\": trial,\n",
    "                \"time\": time,\n",
    "                \"d\": channel.d,\n",
    "                \"Mdist\": np.linalg.norm(channel.Mhat-channel.C),\n",
    "                \"Qdist\": np.linalg.norm(np.dot(channel.Qc.T, channel.Q) - np.eye(3)),\n",
    "                \"pxval\": channel.kx, \"pyval\": channel.ky, \"pzval\": channel.kz,\n",
    "                \"pxhat\": pxhat, \"pyhat\": pyhat, \"pzhat\": pzhat\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(RECORDS)\n",
    "df.to_csv(\"regime2_adaptive_delta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"regime1_adaptive_delta.csv\")\n",
    "df1[\"dpx\"] = np.abs(df1[\"pxval\"] - df1[\"pxhat\"])\n",
    "df1[\"dpy\"] = np.abs(df1[\"pyval\"] - df1[\"pyhat\"])\n",
    "df1[\"dpz\"] = np.abs(df1[\"pzval\"] - df1[\"pzhat\"])\n",
    "\n",
    "v1 = df1.groupby(\"time\").mean()\n",
    "s1 = df1.groupby(\"time\").std()\n",
    "\n",
    "df2 = pd.read_csv(\"regime2_adaptive_delta.csv\")\n",
    "df2[\"dpx\"] = np.abs(df2[\"pxval\"] - df2[\"pxhat\"])\n",
    "df2[\"dpy\"] = np.abs(df2[\"pyval\"] - df2[\"pyhat\"])\n",
    "df2[\"dpz\"] = np.abs(df2[\"pzval\"] - df2[\"pzhat\"])\n",
    "\n",
    "v2 = df2.groupby(\"time\").mean()\n",
    "s2 = df2.groupby(\"time\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(16, 8), sharey=True, sharex=True,\n",
    "                        tight_layout={\"h_pad\": 1.0, \"rect\": [0.0, 0.0, 1.0, 0.95]})\n",
    "for idx, stat in enumerate([\"pxhat\", \"pyhat\", \"pzhat\"]):\n",
    "    t1 = v1[stat].index.values\n",
    "    y1 = v1[stat].values\n",
    "    e1 = s1[stat].values\n",
    "    x = np.log(v1.loc[1:, stat].index.values)\n",
    "    y = np.log(v1.loc[1:, stat].values)\n",
    "    reg = sp.stats.linregress(x, y)\n",
    "    fitted = np.exp(reg.intercept + reg.slope * x)\n",
    "    axs[0, idx].semilogy(t1, y1, ls=\"\", marker=\".\", color=sns.color_palette()[idx], alpha=0.05)\n",
    "    axs[0, idx].semilogy(t1, y1+e1, ls=\"--\", color=sns.color_palette()[idx])\n",
    "    axs[0, idx].semilogy(t1[1:], fitted, ls=\":\", color=sns.color_palette()[idx],\n",
    "                         label=\"{} = {:0.2f} e^({:0.2f}*n)\".format(stat, np.exp(reg.intercept), reg.slope))\n",
    "    axs[0, idx].axhline(df1.loc[0, stat[:2]+\"val\"], color=sns.color_palette()[idx])\n",
    "    axs[0, idx].set_title(stat)\n",
    "    axs[0, idx].legend(frameon=True)\n",
    "    \n",
    "    t2 = v2[stat].index.values\n",
    "    y2 = v2[stat].values\n",
    "    e2 = s2[stat].values\n",
    "    x = np.log(v2.loc[1:, stat].index.values)\n",
    "    y = np.log(v2.loc[1:, stat].values)\n",
    "    reg = sp.stats.linregress(x, y)\n",
    "    fitted = np.exp(reg.intercept + reg.slope * x)\n",
    "    axs[1, idx].semilogy(t2, y2, ls=\"\", marker=\".\", color=sns.color_palette()[idx], alpha=0.05)\n",
    "    axs[1, idx].semilogy(t2, y2+e2, ls=\"--\", color=sns.color_palette()[idx])\n",
    "    axs[1, idx].semilogy(t2[1:], fitted, ls=\":\", color=sns.color_palette()[idx],\n",
    "                         label=\"{} = {:0.2f} e^({:0.2f}*n)\".format(stat, np.exp(reg.intercept), reg.slope))\n",
    "    axs[1, idx].axhline(df2.loc[0, stat[:2]+\"val\"], color=sns.color_palette()[idx])\n",
    "    axs[1, idx].set_xlabel(\"Number of errors\")\n",
    "    axs[1, idx].legend(frameon=True)\n",
    "\n",
    "fig.suptitle(\"Average difference in effective error probability (steps are 1e3, max is 1e6)\")\n",
    "axs[0, 0].set_ylabel(\"kx=0.7, ky=0.2, kz=0.1\")\n",
    "axs[1, 0].set_ylabel(\"kx=0.985, ky=0.01, kz=0.005\")\n",
    "\n",
    "axs[0, 3].semilogy(v1[\"d\"].index.values, v1[\"d\"].values, color=sns.color_palette()[3])\n",
    "axs[1, 3].semilogy(v2[\"d\"].index.values, v2[\"d\"].values, color=sns.color_palette()[3])\n",
    "\n",
    "axs[1, 3].set_title(\"d\")\n",
    "axs[0, 3].set_title(\"d\")\n",
    "\n",
    "axs[1, 3].set_ylabel(\"d\")\n",
    "axs[0, 3].set_ylabel(\"d\")\n",
    "\n",
    "axs[1, 0].set_ylim([0.001, 1.0])\n",
    "axs[0, 0].set_ylim([0.001, 1.0])\n",
    "fig.savefig(\"adaptivedelta_1e3_1e6.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
